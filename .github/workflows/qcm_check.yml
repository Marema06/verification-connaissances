name: CI with Ollama (CPU Mode)

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  build-and-test:
    runs-on: ubuntu-22.04
    timeout-minutes: 30

    steps:
      - name:  Checkout code
        uses: actions/checkout@v4

      # 1. Install Ollama en mode CPU
      - name:  Install Ollama (CPU Mode)
        run: |
          # Installation
          curl -fsSL https://ollama.com/install.sh | OLLAMA_NOBLAS=1 sh

          # Configuration pour mode CPU
          echo "OLLAMA_NOBLAS=1" >> $GITHUB_ENV
          echo "HOME=/github/home" >> $GITHUB_ENV

          # Démarrer le serveur en arrière-plan
          nohup ollama serve > ollama.log 2>&1 &
          echo $! > ollama.pid
          sleep 5

      # 2. Télécharger un modèle optimisé CPU
      - name:  Download CPU-optimized model
        run: |
          ollama pull orca-mini  # Modèle plus léger que llama3
          ollama list

      # 3. Setup Python/Flask
      - name:  Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name:  Install dependencies
        run: |
          pip install -r requirements.txt
          pip install gunicorn

      # 4. Démarrer Flask
      - name:  Start Flask
        env:
          OLLAMA_URL: "http://localhost:11434"
          OLLAMA_MODEL: "orca-mini"
        run: |
          cd backend
          nohup gunicorn --bind 0.0.0.0:5000 --workers 1 app:app > flask.log 2>&1 &
          echo $! > flask.pid

          # Attendre que Flask soit prêt
          for i in {1..10}; do
            if curl -s http://localhost:5000/healthz; then
              echo " Flask ready"
              break
            fi
            sleep 2
          done

      # 5. Test d'intégration
      - name:  Test QCM Generation
        run: |
          curl -X POST http://localhost:5000/generate_qcm \
            -H "Content-Type: application/json" \
            -d '{"code_block":"def hello():\n    print(\\"Hello\\")","author":"github_action"}'

            # ===== CLEANUP =====
      - name:  Stop services
        if: always()
        run: |
          echo "=== Nettoyage des processus ==="

          # Arrêt Flask
          if [ -f backend/flask.pid ]; then
            echo "Arrêt de Flask..."
            kill -9 $(cat backend/flask.pid) 2>/dev/null || true
            rm -f backend/flask.pid
          fi

          # Arrêt Ollama
          if [ -f ollama.pid ]; then
            echo "Arrêt d'Ollama..."
            kill -9 $(cat ollama.pid) 2>/dev/null || true
            rm -f ollama.pid
          fi

          # Nettoyage supplémentaire des processus zombie
          pkill -f "ollama serve" 2>/dev/null || true
          pkill -f "gunicorn" 2>/dev/null || true

          echo "=== Vérification finale ==="
          ps aux | grep -E "ollama|gunicorn" || echo "Aucun processus résiduel trouvé"
