name: CI with Ollama (CPU Mode)

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  build-and-test:
    runs-on: ubuntu-22.04
    timeout-minutes: 60  # Augmenté pour les modèles CPU

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # 1. Installer Ollama en mode CPU
      - name: Install Ollama (CPU Mode)
        run: |
          curl -fsSL https://ollama.com/install.sh | OLLAMA_NOBLAS=1 sh
          echo "OLLAMA_NOBLAS=1" >> $GITHUB_ENV
          echo "HOME=/github/home" >> $GITHUB_ENV

          nohup ollama serve > ollama.log 2>&1 &
          echo $! > ollama.pid

          # Vérification démarrage Ollama
          for i in {1..20}; do
            if curl -s localhost:11434 >/dev/null; then
              echo "Ollama ready after $i attempts"
              break
            fi
            echo "Waiting for Ollama ($i/20)..."
            sleep 5
          done

          if [ $i -eq 20 ]; then
            echo "ERROR: Ollama failed to start"
            cat ollama.log
            exit 1
          fi

      # 2. Télécharger un modèle optimisé CPU
      - name: Download CPU-optimized model
        run: |
          ollama pull tinyllama  # Modèle plus léger pour les tests CI
          ollama list

      # 3. Setup Python/Flask
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt gunicorn

      # 4. Démarrer Flask avec point d'entrée backend/
      - name: Start Flask
        env:
          OLLAMA_BASE_URL: "http://localhost:11434"
          OLLAMA_MODEL: "tinyllama"  # Utilisation du modèle léger
          PYTHONUNBUFFERED: 1
        run: |
          # Vérifier structure fichiers
          echo "Project structure:"
          ls -la

          # Démarrer Gunicorn
          echo "Starting Flask with entrypoint: backend.app:app"
          nohup gunicorn --timeout 600 --bind 0.0.0.0:5000 --workers 1 --log-level debug backend.app:app > flask.log 2>&1 &
          echo $! > flask.pid

          # Vérification démarrage Flask
          for i in {1..30}; do
            # Vérifier processus
            if ! ps -p $(cat flask.pid) > /dev/null; then
              echo "ERROR: Flask process died"
              cat flask.log
              exit 1
            fi

            # Vérifier endpoint healthz
            if curl -s -o /dev/null -w "%{http_code}" http://localhost:5000/healthz | grep -q 200; then
              echo "Flask ready after $i seconds"
              break
            fi

            echo "Waiting for Flask ($i/30)..."
            sleep 2
          done

          if [ $i -eq 30 ]; then
            echo "ERROR: Flask startup timeout"
            echo "=== Flask Log ==="
            cat flask.log
            exit 1
          fi

      # 5. Vérification des connections
      - name: Verify Connections
        run: |
          echo "=== Active Processes ==="
          ps aux | grep -E 'ollama|gunicorn'

          echo "=== Ollama Status ==="
          curl -v http://localhost:11434/api/tags || echo "Ollama check failed"

          echo "=== Flask Debug Endpoint ==="
          curl -v http://localhost:5000/debug || echo "Debug endpoint failed"


      # 7. Cleanup
      - name: Stop services
        if: always()
        run: |
          echo "=== Cleaning up ==="

          # Arrêter Flask
          if [ -f flask.pid ]; then
            echo "Stopping Flask..."
            kill -9 $(cat flask.pid) 2>/dev/null || true
            rm -f flask.pid
          fi

          # Arrêter Ollama
          if [ -f ollama.pid ]; then
            echo "Stopping Ollama..."
            kill -9 $(cat ollama.pid) 2>/dev/null || true
            rm -f ollama.pid
          fi

          # Nettoyage processus
          pkill -f "ollama serve" 2>/dev/null || true
          pkill -f "gunicorn" 2>/dev/null || true

      # 8. Upload logs for debugging
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: service-logs
          path: |
            ollama.log
            flask.log
            curl.log
